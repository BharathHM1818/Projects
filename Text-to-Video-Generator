!pip install diffusers transformers accelerate torch

import torch
from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler
from diffusers.utils import export_to_video

pipe = DiffusionPipeline.from_pretrained("damo-vilab/text-to-video-ms-1.7b", torch_dtype=torch.float16, variant="fp16")
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
pipe.enable_model_cpu_offload()


# Define constants
prompt = "dog eating pizza"
num_inference_steps = 25  # Number of inference steps
frame_duration = 0.1  # Duration of each frame in seconds
desired_duration = 10.0  # Desired duration of the output video in seconds

# Assume pipe and export_to_video functions are defined elsewhere
# Also assume you have a function to calculate FPS based on desired duration

def calculate_fps(total_frames, desired_duration):
    return total_frames / desired_duration

# Generate video frames
start_time = time.time()
video_frames = pipe(prompt, num_inference_steps=num_inference_steps).frames
end_time = time.time()
total_time = end_time - start_time

# Reshape frames
video_frames_list = video_frames.reshape(-1, 256, 256, 3)

# Calculate total frame count
total_frames = video_frames_list.shape[0]

# Calculate FPS based on desired duration
fps = calculate_fps(total_frames, desired_duration)

# Export to video with specified duration
video_path = export_to_video(video_frames_list, fps=fps)

# Adjust video name (if necessary)
video_name = video_path.replace('/tap', '')

# Output results
print("Name:", video_name)
print(f"Total frames: {total_frames}, Duration: {desired_duration:.2f} seconds")
print(f"Inference time: {total_time:.2f} seconds")

# Optionally clear CUDA cache if using GPU
torch.cuda.empty_cache()

import time

from google.colab import drive
drive.mount('/content/drive')

